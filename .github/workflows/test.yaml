name: Tube unit-test
on: push

jobs:
  # Label of the container job
  runner-job:
    # Containers must run in Linux based operating systems
    runs-on: ubuntu-latest
    # Service containers to run with `container-job`
    services:
      # Label used to access the service container
      postgres:
        # Docker Hub image
        image: postgres:13.7
        # Provide the password for postgres
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: metadata_db
        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # Maps tcp port 5432 on service container to the host
          - 5432:5432

    steps:
      # Downloads a copy of the code in your repository before running CI tests
      - name: Check out repository code
        uses: actions/checkout@v3
      - name: install psql
        run: |
          sudo apt-get update
          sudo apt-get install --yes --no-install-recommends postgresql-client libffi-dev libssl-dev libssl1.1 libgnutls30
          sudo apt-get --only-upgrade install libpq-dev
      # Performs a clean installation of all dependencies in the `package.json` file
      # For more information, see https://docs.npmjs.com/cli/ci.html
      - name: Make dir cor compose-etl
        working-directory: ..
        run: git clone https://github.com/uc-cdis/compose-etl.git --branch feat/spark3 --single-branch
      - name: Get all files
        run: ls ..
      - name: Get all files
        run: ls ../..
      - name: Get current directory
        run: pwd
      - name: Install and copy files
        run: |
          cp -f tests/gen3/tube/etlMapping.yaml ../compose-etl/configs/etlMapping.yaml
          cp -f tests/gen3/tube/user.yaml ../compose-etl/configs/user.yaml
      - name: Init postgres database
        run: psql -d postgresql://postgres:postgres@localhost/metadata_db -f tests/metadata_db.sql
      - name: install jq
        run: sudo apt install -y jq
      - name: Create credential file
        working-directory: ../compose-etl
        run: echo "{\"db_host\":\"host.docker.internal\",\"db_username\":\"postgres\",\"db_password\":\"postgres\",\"db_database\":\"metadata_db\"}" > configs/creds.json
      - name: Replace tube branch
        working-directory: ../compose-etl
        run: sed -i "s/tube:master/tube:${BRANCH//\//_}/g" docker-compose.yml
      - name: change max_map_count
        working-directory: ../compose-etl
        run: sudo sysctl -w vm.max_map_count=262144
      - name: Installation with poetry
        run: |
          sudo apt-get -y install python3.9 python3-testresources
          sudo ln -s -f $(which python3.9) /usr/bin/python
          sudo ln -s -f $(which python3.9) /usr/bin/python3
          curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
          python3.9 get-pip.py --user
          sudo apt-get -y install python3.9-distutils
          sudo ln -s -f $(which pip3) /usr/bin/pip
          pip install --upgrade poetry
          poetry config virtualenvs.create false
          poetry install -vv --no-interaction
      - name: Run spark and ElasticSearch
        working-directory: ../compose-etl
        run: docker-compose up -d spark elasticsearch
      - name: wait for the container up and running
        run: sleep 60
      - name: checking with log
        working-directory: ../compose-etl
        run: docker-compose logs
      - name: check all container
        run: docker ps
      - name: check all docker network
        run: docker network ls
      - name: Make XDG_DATA_HOME's tube
        run: mkdir -p $XDG_DATA_HOME/gen3/tube
        env:
          XDG_DATA_HOME: /home/runner/work/tube
      - name: Copy file to the XDG_DATA_HOME folder
        run: cp tests/gen3/tube/{creds.json,etlMapping.yaml,user.yaml} $XDG_DATA_HOME/gen3/tube/
        env:
          XDG_DATA_HOME: /home/runner/work/tube
      - name: Run etl process
        working-directory: ../compose-etl
        run: docker-compose run tube bash -c "python run_config.py; python run_etl.py"
      - name: Run test
        # Runs a script that creates a PostgreSQL table, populates
        # the table with data, and then retrieves the data.
        run: python -m pytest -v tests -m "not ssl"
        # Environment variables used by the `client.js` script to create a new PostgreSQL table.
        env:
          # The hostname used to communicate with the PostgreSQL service container
          ES_URL: localhost
          # The default PostgreSQL port
          POSTGRES_PORT: 5432
          DICTIONARY_URL: https://s3.amazonaws.com/dictionary-artifacts/ndhdictionary/3.3.8/schema.json
          XDG_DATA_HOME: /home/runner/work/tube
          ES_INDEX_NAME: etl
