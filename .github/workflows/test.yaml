name: Tube unit-test
on: push

jobs:
  # Label of the container job
  runner-job:
    # Containers must run in Linux based operating systems
    runs-on: ubuntu-latest
    # Service containers to run with `container-job`
    services:
      # Label used to access the service container
      postgres:
        # Docker Hub image
        image: postgres
        # Provide the password for postgres
        env:
          POSTGRES_PASSWORD: postgres
        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # Maps tcp port 5432 on service container to the host
          - 5432:5432

    steps:
      # Downloads a copy of the code in your repository before running CI tests
      - name: Check out repository code
        uses: actions/checkout@v3

      # Performs a clean installation of all dependencies in the `package.json` file
      # For more information, see https://docs.npmjs.com/cli/ci.html
      - name: Clone docker-compose
        run: git clone https://github.com/uc-cdis/compose-etl.git --branch master --single-branch
      - name: Copy etlMapping file
        run: cp -f tests/gen3/tube/etlMapping.yaml compose-etl/configs/etlMapping.yaml
      - name: Copy user.yaml file
        run: cp -f tests/gen3/tube/user.yaml compose-etl/configs/user.yaml
      - name: Copy user.yaml file
        run: ls
      - name: Copy user.yaml file
        run: ls tube
      - name: Create credential file
        working-directory: ./compose-etl
        run: echo "{\"db_host\":\"postgres\",\"db_username\":\"postgres\",\"db_password\":\"postgres\",\"db_database\":\"metadata_db\"}" > configs/creds.json
      - name: Replace tube branch
        working-directory: ./compose-etl
        run: sed -i "s/tube:master/tube:${BRANCH//\//_}/g" docker-compose.yml
      - name: change max_map_count
        working-directory: ./compose-etl
        run: sudo sysctl -w vm.max_map_count=262144
      - name: Run spark and ElasticSearch
        working-directory: ./compose-etl
        run: docker-compose up -d spark elasticsearch
      - name: wait for the container up and running
        run: sleep 60
      - name: checking with log
        working-directory: ./compose-etl
        run: docker-compose logs
      - name: Run etl process
        working-directory: ./compose-etl
        run: docker-compose run tube bash -c "python run_config.py; python run_etl.py"
      - name: XDG_DATA_HOME
        run: export XDG_DATA_HOME="$HOME/.local/share"
      - name: ES_INDEX_NAME
        run: export ES_INDEX_NAME="etl"
      - name: Make XDG_DATA_HOME's tube
        run: mkdir -p $XDG_DATA_HOME/gen3/tube
      - name: Copy file to the XDG_DATA_HOME folder
        run: cp tests/gen3/tube/{creds.json,etlMapping.yaml,user.yaml} $XDG_DATA_HOME/gen3/tube/

      - name: Run test
        # Runs a script that creates a PostgreSQL table, populates
        # the table with data, and then retrieves the data.
        run: python -m pytest -v tests
        # Environment variables used by the `client.js` script to create a new PostgreSQL table.
        env:
          # The hostname used to communicate with the PostgreSQL service container
          ES_URL: localhost
          # The default PostgreSQL port
          POSTGRES_PORT: 5432
          DICTIONARY_URL: https://s3.amazonaws.com/dictionary-artifacts/ndhdictionary/3.3.8/schema.json
