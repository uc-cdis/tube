name: Build image and push to Quay and run unit-test
on: push

jobs:
  # Label of the container job
  ci:
    name: Build Image and Push to Quay
    uses: uc-cdis/.github/.github/workflows/image_build_push.yaml@master
    secrets:
      ECR_AWS_ACCESS_KEY_ID: ${{ secrets.ECR_AWS_ACCESS_KEY_ID }}
      ECR_AWS_SECRET_ACCESS_KEY: ${{ secrets.ECR_AWS_SECRET_ACCESS_KEY }}
      QUAY_USERNAME: ${{ secrets.QUAY_USERNAME }}
      QUAY_ROBOT_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
  runner-job:
    # Containers must run in Linux based operating systems
    runs-on: ubuntu-20.04
    needs: ci
    # Service containers to run with `container-job`
    services:
      # Label used to access the service container
      postgres:
        # Docker Hub image
        image: postgres:13
        # Provide the password for postgres
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: metadata_db
        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # Maps tcp port 5432 on service container to the host
          - 5432:5432
    steps:
      # Downloads a copy of the code in your repository before running CI tests
      - name: Check out repository code
        uses: actions/checkout@v3
      - name: Installing dependencies
        run: |
          sudo apt-get update
          sudo apt-get install --yes --no-install-recommends jq postgresql-client python3.9 python3-pip
          sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.9 1
          sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1
      - name: Make dir cor compose-etl
        working-directory: ..
        run: git clone https://github.com/uc-cdis/compose-etl.git --branch master --single-branch
      - name: Get all files
        run: ls ..
      - name: Get all files
        run: ls ../..
      - name: Get current directory
        run: pwd
      - name: Extract branch name
        shell: bash
        run: echo "##[set-output name=branch;]$(echo ${GITHUB_REF#refs/heads/})"
        id: extract_branch
      - name: Copy configuration files
        run: |
          cp -f tests/gen3/tube/etlMapping.yaml ../compose-etl/configs/etlMapping.yaml
          cp -f tests/gen3/tube/user.yaml ../compose-etl/configs/user.yaml
      - name: Init postgres database
        run: psql -d postgresql://postgres:postgres@localhost/metadata_db -f tests/metadata_db.sql
      - name: Create credential file
        working-directory: ../compose-etl
        run: echo "{\"db_host\":\"host.docker.internal\",\"db_username\":\"postgres\",\"db_password\":\"postgres\",\"db_database\":\"metadata_db\"}" > configs/creds.json
      - name: Replace tube branch
        working-directory: ../compose-etl
        run: |
          BRANCH=${{ steps.extract_branch.outputs.branch }}
          sed -i "s/tube:master/tube:${BRANCH//\//_}/g" docker-compose.yml
      - name: change max_map_count (needed for running Elasticsearch in container)
        working-directory: ../compose-etl
        run: sudo sysctl -w vm.max_map_count=262144
      - name: Install poetry, dependencies and tube
        run: |
          python3.9 -m pip install --upgrade pip poetry requests
          python3.9 -m poetry config virtualenvs.create true
          python3.9 -m poetry install -vv --no-interaction --with dev
      - name: Run spark and ElasticSearch
        working-directory: ../compose-etl
        run: docker-compose up -d spark elasticsearch
      - name: Wait for the container to be up and running
        run: sleep 60
      - name: Checking logs
        working-directory: ../compose-etl
        run: docker-compose logs
      - name: Check all container
        run: docker ps
      - name: Check all docker network
        run: docker network ls
      - name: Make XDG_DATA_HOME's tube
        run: mkdir -p $XDG_DATA_HOME/gen3/tube
        env:
          XDG_DATA_HOME: /home/runner/work/tube
      - name: Copy file to the XDG_DATA_HOME folder
        run: cp tests/gen3/tube/{creds.json,etlMapping.yaml,user.yaml} $XDG_DATA_HOME/gen3/tube/
        env:
          XDG_DATA_HOME: /home/runner/work/tube
      - name: Run etl process
        working-directory: ../compose-etl
        run: docker-compose run tube bash -c "python run_config.py; python run_etl.py"
      - name: Run tests
        # Runs a script that creates a PostgreSQL table, populates
        # the table with data, and then retrieves the data.
        run: python3.9 -m poetry run pytest -v tests -m "not ssl"
        # Environment variables used by the `client.js` script to create a new PostgreSQL table.
        env:
          # The hostname used to communicate with the PostgreSQL service container
          ES_URL: localhost
          # The default PostgreSQL port
          POSTGRES_PORT: 5432
          DICTIONARY_URL: https://s3.amazonaws.com/dictionary-artifacts/ndhdictionary/3.3.8/schema.json
          XDG_DATA_HOME: /home/runner/work/tube
          ES_INDEX_NAME: etl
